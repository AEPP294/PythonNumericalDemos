{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://github.com/GeostatsGuy/GeostatsPy/blob/master/TCG_color_logo.png?raw=true\" width=\"220\" height=\"240\" />\n",
    "\n",
    "</p>\n",
    "\n",
    "## Convolutional Neural Network Operations\n",
    "\n",
    "\n",
    "### Michael Pyrcz, Associate Professor, University of Texas at Austin \n",
    "\n",
    "##### [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)\n",
    "\n",
    "\n",
    "### Convolutional Neural Network Operators\n",
    "\n",
    "Here's a simple workflow with an image (of my jeep) and the following convolutional neural network operators:\n",
    "\n",
    "* convolution - a variety of filtersto detect features\n",
    "\n",
    "* pooling - max pooling for dimensionality reduction\n",
    "\n",
    "* activation - activation function to impart nonlinearity into the system, without activations, convolutions would collapse to a single convolution!\n",
    "\n",
    "#### Objective \n",
    "\n",
    "I teach data analytics, geostatistics and machine learning. To demonstrate the basic operators applied in convolutional neural networks.  \n",
    "\n",
    "* I use these examples in my lecture notes, see the lecture posted on my YouTube channel.\n",
    "\n",
    "* gain experiential learning with the nuts and bolts of convolutional neural networks\n",
    "\n",
    "Note, I just demonstrate the operators. There is no attempt to compile the steps into a practice convolutional neural network architecture.\n",
    "\n",
    "#### Getting Started\n",
    "\n",
    "Here's the steps to get setup in Python with the GeostatsPy package:\n",
    "\n",
    "1. Install Anaconda 3 on your machine (https://www.anaconda.com/download/). \n",
    "2. From Anaconda Navigator (within Anaconda3 group), go to the environment tab, click on base (root) green arrow and open a terminal. \n",
    "3. In the terminal type: pip install geostatspy. \n",
    "4. Open Jupyter and in the top block get started by copy and pasting the code block below from this Jupyter Notebook to start using the geostatspy functionality. \n",
    "\n",
    "You will need to copy the image file to your working directory.  They are available here:\n",
    "\n",
    "* Image File - [maple_side.jpg](https://github.com/GeostatsGuy/GeoDataSets/blob/master/maple_side.jpg)\n",
    "\n",
    "There are exampled below with these functions. You can go here to see a list of the available functions, https://git.io/fh4eX, other example workflows and source code. \n",
    "\n",
    "#### Load the required libraries\n",
    "\n",
    "The following code loads the required libraries.\n",
    "\n",
    "* we will need some standard packages. These should have been installed with Anaconda 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                               # to set current working directory \n",
    "import sys                                              # supress output to screen\n",
    "import numpy as np                                      # arrays and matrix math\n",
    "import pandas as pd                                     # DataFrames\n",
    "import matplotlib.pyplot as plt                         # plotting\n",
    "import matplotlib.gridspec as gridspec                  # control of subplot sizes\n",
    "from ipywidgets import interactive                      # widgets and interactivity, I will make an intera\n",
    "from ipywidgets import widgets                            \n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import Label\n",
    "from ipywidgets import VBox, HBox\n",
    "\n",
    "from PIL import Image                                   # loading and working with images\n",
    "from scipy import ndimage\n",
    "import skimage.measure\n",
    "import sklearn.preprocessing\n",
    "from tensorflow.keras.layers import LeakyReLU           # activation function\n",
    "#import matplotlib as mpl                               # option to increase image resolution, but slows application greatly\n",
    "#mpl.rcParams['figure.dpi'] = 300                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing 'python -m pip install [package-name]'. More assistance is available with the respective package docs.  \n",
    "\n",
    "#### Set the working directory\n",
    "\n",
    "I always like to do this so I don't lose files and to simplify subsequent read and writes (avoid including the full address each time).  Also, in this case make sure to place the required (see above) GSLIB executables in this directory or a location identified in the environmental variable *Path*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"c:/PGE383\")                                   # set the working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Image Data\n",
    "\n",
    "We will load an image of my jeep.  Note, the application has been calibrated for my jeep images:\n",
    "\n",
    "* their specific scale and position \n",
    "\n",
    "No attempt was made to generalize this application to any image.  \n",
    "\n",
    "* the original wheel / tire specs and locations and sizes could be used or \n",
    "\n",
    "* an interesting machine learning problem to automatically find the current wheels and to modify them\n",
    "\n",
    "Let's load those images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"maple_side.jpg\")                      # load jeep images from the current directory    \n",
    "width, height = img.size                                # get the sizes of the images\n",
    "\n",
    "print(\"Array shape: (\" +str(img.size[1]) + \",\" + str(img.size[0]) +\")\")\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=5.0, top=5.8, wspace=0.1, hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Image to ndarray\n",
    "\n",
    "Let's convert the image to an ndarray so we can apply the various iomage operations applied in convolutional neurnetworks.\n",
    "\n",
    "* note we will have 3 channels for RGB instensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_img = np.array(img)\n",
    "\n",
    "print(\"Array shape: \" +str(nd_img.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the Imaged to Black and White\n",
    "\n",
    "We convert the image to a gray scale \n",
    "\n",
    "* I use the lambda function by unutby from [stackoverflow](https://stackoverflow.com/questions/12201577/how-can-i-convert-an-rgb-image-into-grayscale-in-python)\n",
    "\n",
    "* we use the inferno colar scheme, because it is awesome and assists with observing contrasts while color blind friendly and without resulting in bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = lambda rgb : np.dot(rgb[... , :3] , [0.299 , 0.587, 0.114]) # conversion function by unutbu\n",
    "\n",
    "bw_nd_img = gray(nd_img)                                      # apply the function to the image\n",
    "print(\"Array shape: \" +str(bw_nd_img.shape))\n",
    "\n",
    "plt.imshow(bw_nd_img, cmap='inferno')\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=5.0, top=5.8, wspace=0.1, hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMaxNormalization\n",
    "\n",
    "Normalize the values to have a minimum of -1.0 and a maximum of 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (-1.0,1.0)).fit(bw_nd_img)\n",
    "st_bw_nd_img = scaler.transform(bw_nd_img)\n",
    "\n",
    "print(\"Array shape: \" +str(st_bw_nd_img.shape))\n",
    "\n",
    "plt.subplot(121)\n",
    "im1 = plt.imshow(bw_nd_img, cmap='inferno',vmin=0.0,vmax=255.0)\n",
    "plt.colorbar(im1,fraction=0.025, pad=0.04)\n",
    "\n",
    "plt.subplot(122)\n",
    "im2 = plt.imshow(st_bw_nd_img, cmap='inferno',vmin=-1.0,vmax=1.0)\n",
    "plt.colorbar(im2,fraction=0.025, pad=0.04)\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=5.0, top=2.8, wspace=0.1, hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution\n",
    "\n",
    "Let's demonstrate convolution.\n",
    "\n",
    "* you can modify the convolution filter\n",
    "\n",
    "function from https://medium.com/analytics-vidhya/2d-convolution-using-python-numpy-43442ff5f381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import correlate1d\n",
    "import sklearn\n",
    "\n",
    "filter_type = \"edge\"\n",
    "\n",
    "if filter_type == \"custom\":\n",
    "    conv_filter = np.array([[0, -2, 0],\n",
    "                            [-2, 10, -2],\n",
    "                            [0, -2, 0]])\n",
    "\n",
    "elif filter_type == \"gradient_hori\":\n",
    "    conv_filter = np.array([[2, 1, -1],\n",
    "                            [2, 1, -1],\n",
    "                            [2, 1, -1]])\n",
    "    \n",
    "elif filter_type == \"gradient_vert\":\n",
    "    conv_filter = np.array([[2, 2, 2],\n",
    "                            [1, 1, 1],\n",
    "                            [-1, -1, -1]])\n",
    "\n",
    "elif filter_type == \"edge\":\n",
    "    conv_filter = np.array([[-1, -1, -1], \n",
    "                           [-1, 8, -1], \n",
    "                           [-1, -1, -1]])\n",
    "    \n",
    "elif filter_type == \"sharpen\":\n",
    "    conv_filter = np.array([[-1, -1, -1], \n",
    "                           [-1, 9, -1], \n",
    "                           [-1, -1, -1]])\n",
    "    \n",
    "elif filter_type == \"blur\":\n",
    "    conv_filter = np.array([[1/9, 1/9, 1/9], \n",
    "                           [1/9, 1/9, 1/9], \n",
    "                           [1/9, 1/9, 1/9]])\n",
    "      \n",
    "conv_bw_nd_img = ndimage.convolve(st_bw_nd_img,weights=conv_filter)\n",
    "\n",
    "print(\"Array shape: \" + str(conv_bw_nd_img.shape))\n",
    "\n",
    "plt.subplot(121)\n",
    "im1 = plt.imshow(st_bw_nd_img, cmap='inferno',vmin=-1.0,vmax=1.0)\n",
    "plt.colorbar(im1,fraction=0.025, pad=0.04)\n",
    "\n",
    "plt.subplot(122)\n",
    "im2 = plt.imshow(conv_bw_nd_img, cmap='inferno',vmin=-1.0,vmax=1.0)\n",
    "plt.colorbar(im2,fraction=0.025, pad=0.04)\n",
    "\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=5.0, top=2.8, wspace=0.1, hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Pooling\n",
    "\n",
    "Reduce the number of nodes by taking the maximum value over a window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_bw_nd_img = maximum_filter(bw_nd_img,size=(11,11))\n",
    "window_size = 21\n",
    "maxpool_bw_nd_img = skimage.measure.block_reduce(st_bw_nd_img, (window_size,window_size), np.max)\n",
    "\n",
    "plt.subplot(121)\n",
    "im1 = plt.imshow(st_bw_nd_img, cmap='inferno',vmin=-1.0,vmax=1.0)\n",
    "plt.colorbar(im1,fraction=0.025, pad=0.04)\n",
    "\n",
    "plt.subplot(122)\n",
    "im2 = plt.imshow(maxpool_bw_nd_img, cmap='inferno',vmin=-1.0,vmax=1.0)\n",
    "plt.colorbar(im2,fraction=0.025, pad=0.04)\n",
    "\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=5.0, top=2.8, wspace=0.1, hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Function\n",
    "\n",
    "We borrow the leaky ReLU activation function from TensorFlow and apply it to our normalized image\n",
    "\n",
    "* note, for alpha = 0.0, Leaky ReLU is ReLU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_bw_nd_img = LeakyReLU(alpha=0.0)(st_bw_nd_img)\n",
    "\n",
    "plt.subplot(121)\n",
    "im1 = plt.imshow(st_bw_nd_img, cmap='inferno',vmin=-1.0,vmax=1.0)\n",
    "plt.colorbar(im1,fraction=0.025, pad=0.04)\n",
    "\n",
    "plt.subplot(122)\n",
    "im2 = plt.imshow(act_bw_nd_img, cmap='inferno',vmin=-1.0,vmax=1.0)\n",
    "plt.colorbar(im2,fraction=0.025, pad=0.04)\n",
    "\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=5.0, top=2.8, wspace=0.1, hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "This was a basic demonstration of the operators applied in convolutional neural networks. \n",
    "\n",
    "Much more could be done, I have other demonstrations on the basics of working with DataFrames, ndarrays, univariate statistics, plotting data, declustering, data transformations and many other workflows available at https://github.com/GeostatsGuy/PythonNumericalDemos and https://github.com/GeostatsGuy/GeostatsPy. \n",
    "  \n",
    "#### The Author:\n",
    "\n",
    "### Michael Pyrcz, Associate Professor, University of Texas at Austin \n",
    "*Novel Data Analytics, Geostatistics and Machine Learning Subsurface Solutions*\n",
    "\n",
    "With over 17 years of experience in subsurface consulting, research and development, Michael has returned to academia driven by his passion for teaching and enthusiasm for enhancing engineers' and geoscientists' impact in subsurface resource development. \n",
    "\n",
    "For more about Michael check out these links:\n",
    "\n",
    "#### [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)\n",
    "\n",
    "#### Want to Work Together?\n",
    "\n",
    "I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.\n",
    "\n",
    "* Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I'd be happy to drop by and work with you! \n",
    "\n",
    "* Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PIs including Profs. Foster, Torres-Verdin and van Oort)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!\n",
    "\n",
    "* I can be reached at mpyrcz@austin.utexas.edu.\n",
    "\n",
    "I'm always happy to discuss,\n",
    "\n",
    "*Michael*\n",
    "\n",
    "Michael Pyrcz, Ph.D., P.Eng. Associate Professor The Hildebrand Department of Petroleum and Geosystems Engineering, Bureau of Economic Geology, The Jackson School of Geosciences, The University of Texas at Austin\n",
    "\n",
    "#### More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
